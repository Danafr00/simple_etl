{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba32471c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import mysql.connector\n",
    "import psycopg2\n",
    "import pymysql\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ec20aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pymysql.install_as_MySQLdb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc2c883d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract():\n",
    "    try:\n",
    "        src_conn = mysql.connector.connect(database=\"testing_minimarket\",\n",
    "                        host=\"localhost\",\n",
    "                        user=\"root\",\n",
    "                        password=\"admin123\",\n",
    "                        port=\"3306\")\n",
    "        src_cursor = src_conn.cursor()\n",
    "        src_cursor.execute(\"\"\"SELECT table_name FROM information_schema.tables\n",
    "               WHERE table_schema = 'public'\"\"\")\n",
    "        for tbl in src_cursor.fetchall():\n",
    "            df=pd.read_sql_query('select * from '+ tbl[0], src_conn)\n",
    "            load(df,tbl[0])\n",
    "    except Exception as e:\n",
    "        print(\"Data extract error: \" + str(e))\n",
    "    finally:\n",
    "        src_conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6d08ee0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(df, tbl):\n",
    "    try:\n",
    "        rows_imported = 0\n",
    "        engine = psycopg2.connect(database=\"airflow\",\n",
    "                        host=\"localhost\",\n",
    "                        user=\"airflow\",\n",
    "                        password=\"airflow\",\n",
    "                        port=\"5432\")\n",
    "        print(f'Importing rows {rows_imported} to {rows_imported + len(df)}... for table {tbl}')\n",
    "        df.to_sql(f'{tbl}', engine, if_exists='replace', index=False)\n",
    "        rows_imported += len(df)\n",
    "        print(\"Data imported successful\")\n",
    "    except Exception as e:\n",
    "        print(\"Data load error: \", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "12385f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    extract()\n",
    "except Exception as e:\n",
    "    print(\"Error while extracting data: \", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ba1c4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e957ac44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501ccbf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1754cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract():\n",
    "    try:\n",
    "        src_conn = psycopg2.connect(database=\"Supermarket_DB\",\n",
    "                        host=\"localhost\",\n",
    "                        user=\"postgres\",\n",
    "                        password=\"danafr@010400\",\n",
    "                        port=\"5432\")\n",
    "        src_cursor = src_conn.cursor()\n",
    "        src_cursor.execute(\"\"\"SELECT table_name FROM information_schema.tables\n",
    "               WHERE table_schema = 'public'\"\"\")\n",
    "        for tbl in src_cursor.fetchall():\n",
    "            df=pd.read_sql_query('select * from '+ tbl[0], src_conn)\n",
    "            load(df,tbl[0])\n",
    "    except Exception as e:\n",
    "        print(\"Data extract error: \" + str(e))\n",
    "    finally:\n",
    "        src_conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19c019d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(df, tbl):\n",
    "    try:\n",
    "        rows_imported = 0\n",
    "        engine = create_engine(\"mysql://{0}:{1}@{2}:{3}/{4}?charset=utf8\".format(\"root\", \"admin123\", \"localhost\", 3306, \"supermarket_db\"))\n",
    "        print(f'Importing rows {rows_imported} to {rows_imported + len(df)}... for table {tbl}')\n",
    "        df.to_sql(f'{tbl}', engine, if_exists='replace', index=False)\n",
    "        rows_imported += len(df)\n",
    "        print(\"Data imported successful\")\n",
    "    except Exception as e:\n",
    "        print(\"Data load error: \", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06badf57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing rows 0 to 793... for table customer\n",
      "Data imported successful\n",
      "Importing rows 0 to 1862... for table product\n",
      "Data imported successful\n",
      "Importing rows 0 to 9994... for table sales\n",
      "Data imported successful\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    extract()\n",
    "except Exception as e:\n",
    "    print(\"Error while extracting data: \", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "773f1b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from airflow.hooks.base import BaseHook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f7c8b11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[34m2022-07-11 15:47:56,717\u001b[0m] {\u001b[34mconnection.py:\u001b[0m427} ERROR\u001b[0m - Unable to retrieve connection from secrets backend (MetastoreBackend). Checking subsequent secrets backend.\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kana\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 1706, in _execute_context\n",
      "    cursor, statement, parameters, context\n",
      "  File \"C:\\Users\\kana\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sqlalchemy\\engine\\default.py\", line 716, in do_execute\n",
      "    cursor.execute(statement, parameters)\n",
      "sqlite3.OperationalError: no such table: connection\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kana\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\airflow\\models\\connection.py\", line 420, in get_connection_from_secrets\n",
      "    conn = secrets_backend.get_connection(conn_id=conn_id)\n",
      "  File \"C:\\Users\\kana\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\airflow\\utils\\session.py\", line 71, in wrapper\n",
      "    return func(*args, session=session, **kwargs)\n",
      "  File \"C:\\Users\\kana\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\airflow\\secrets\\metastore.py\", line 36, in get_connection\n",
      "    conn = session.query(Connection).filter(Connection.conn_id == conn_id).first()\n",
      "  File \"C:\\Users\\kana\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sqlalchemy\\orm\\query.py\", line 2734, in first\n",
      "    return self.limit(1)._iter().first()\n",
      "  File \"C:\\Users\\kana\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sqlalchemy\\orm\\query.py\", line 2821, in _iter\n",
      "    execution_options={\"_sa_orm_load_options\": self.load_options},\n",
      "  File \"C:\\Users\\kana\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sqlalchemy\\orm\\session.py\", line 1670, in execute\n",
      "    result = conn._execute_20(statement, params or {}, execution_options)\n",
      "  File \"C:\\Users\\kana\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 1520, in _execute_20\n",
      "    return meth(self, args_10style, kwargs_10style, execution_options)\n",
      "  File \"C:\\Users\\kana\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sqlalchemy\\sql\\elements.py\", line 314, in _execute_on_connection\n",
      "    self, multiparams, params, execution_options\n",
      "  File \"C:\\Users\\kana\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 1399, in _execute_clauseelement\n",
      "    cache_hit=cache_hit,\n",
      "  File \"C:\\Users\\kana\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 1749, in _execute_context\n",
      "    e, statement, parameters, cursor, context\n",
      "  File \"C:\\Users\\kana\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 1930, in _handle_dbapi_exception\n",
      "    sqlalchemy_exception, with_traceback=exc_info[2], from_=e\n",
      "  File \"C:\\Users\\kana\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sqlalchemy\\util\\compat.py\", line 211, in raise_\n",
      "    raise exception\n",
      "  File \"C:\\Users\\kana\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 1706, in _execute_context\n",
      "    cursor, statement, parameters, context\n",
      "  File \"C:\\Users\\kana\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sqlalchemy\\engine\\default.py\", line 716, in do_execute\n",
      "    cursor.execute(statement, parameters)\n",
      "sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such table: connection\n",
      "[SQL: SELECT connection.password AS connection_password, connection.extra AS connection_extra, connection.id AS connection_id, connection.conn_id AS connection_conn_id, connection.conn_type AS connection_conn_type, connection.description AS connection_description, connection.host AS connection_host, connection.schema AS connection_schema, connection.login AS connection_login, connection.port AS connection_port, connection.is_encrypted AS connection_is_encrypted, connection.is_extra_encrypted AS connection_is_extra_encrypted \n",
      "FROM connection \n",
      "WHERE connection.conn_id = ?\n",
      " LIMIT ? OFFSET ?]\n",
      "[parameters: ('postgres', 1, 0)]\n",
      "(Background on this error at: http://sqlalche.me/e/14/e3q8)\n"
     ]
    },
    {
     "ename": "AirflowNotFoundException",
     "evalue": "The conn_id `postgres` isn't defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAirflowNotFoundException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-0597f9a7f5d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mconn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBaseHook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_connection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'postgres'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\airflow\\hooks\\base.py\u001b[0m in \u001b[0;36mget_connection\u001b[1;34m(cls, conn_id)\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mairflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mConnection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m         \u001b[0mconn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_connection_from_secrets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m         \u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Using connection ID '%s' for task execution.\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconn_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\airflow\\models\\connection.py\u001b[0m in \u001b[0;36mget_connection_from_secrets\u001b[1;34m(cls, conn_id)\u001b[0m\n\u001b[0;32m    428\u001b[0m                 )\n\u001b[0;32m    429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 430\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mAirflowNotFoundException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"The conn_id `{conn_id}` isn't defined\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAirflowNotFoundException\u001b[0m: The conn_id `postgres` isn't defined"
     ]
    }
   ],
   "source": [
    "conn = BaseHook.get_connection('postgres')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2485b84f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_env] *",
   "language": "python",
   "name": "conda-env-tensorflow_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
